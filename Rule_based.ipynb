{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saraxmartin/NegExES/blob/main/Rule_based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99MKArwd5UoT"
      },
      "source": [
        "# RULE-BASED APPROACH\n",
        "Student 1: Sara Martín (NIU:1669812)\n",
        "\n",
        "Student 2: Amelia Gomez (NIU:1631745)\n",
        "\n",
        "Student 3: Aina Navarro (NIU:1670797)\n",
        "\n",
        "Student 4: Lara Rodríguez (NIU: 1667906)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe3Rmu2vxSKA"
      },
      "source": [
        "## Functionalities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/saraxmartin/NegExES.git"
      ],
      "metadata": {
        "id": "rzv8UPJRf23r",
        "outputId": "e8e02d3c-6064-483c-f609-76cdb40a6cd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NegExES'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 41 (delta 19), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (41/41), 1.92 MiB | 3.62 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88EEjn-vyJTA"
      },
      "outputs": [],
      "source": [
        "!pip install spacy\n",
        "!pip install pyspellchecker\n",
        "!pip install -U spacy\n",
        "!python -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3IKyO6BIxaK-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import spacy\n",
        "from spellchecker import SpellChecker\n",
        "# Load the Spanish language model from spaCy\n",
        "nlp = spacy.load(\"es_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLJFowJuxRwJ"
      },
      "outputs": [],
      "source": [
        "def correct_mispellings(words):\n",
        "    \"\"\"\n",
        "    Correct spelling mistakes for each word in a list\n",
        "    \"\"\"\n",
        "    # Initialize a spell checker for Spanish\n",
        "    spell = SpellChecker(language=\"es\")\n",
        "    # Correct the spelling mistakes in each word\n",
        "    corrected_words = []\n",
        "    for word in words:\n",
        "        # Tokenize the word using spaCy\n",
        "        doc = nlp(word)\n",
        "        corrected_word = \"\"\n",
        "        for token in doc:\n",
        "            # Check if the token is a misspelled word\n",
        "            if not token.is_alpha or token.text.lower() in spell:\n",
        "                corrected_word += token.text\n",
        "            else:\n",
        "                print(token.text.lower())\n",
        "                # Correct the spelling using the spell checker\n",
        "                corrected_word += spell.correction(token.text.lower())\n",
        "                print(corrected_word)\n",
        "        corrected_words.append(corrected_word)\n",
        "    return corrected_words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzWonCGE5QRo"
      },
      "source": [
        "# Data pre-processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create datasets for medical terminology"
      ],
      "metadata": {
        "id": "JVgcYmJH9zSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "medicalterms_es = set()\n",
        "medicalterms_cat = set()\n",
        "\n",
        "directory = '/content/NegExES/data/termcat_terminologies'\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.xml'):\n",
        "        # Construct the full path to the XML file\n",
        "        file_path = os.path.join(directory, filename)\n",
        "\n",
        "        # Parse the XML file\n",
        "        tree = ET.parse(file_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        # Iterate over each 'fitxa' element\n",
        "        for fitxa in root.findall('.//fitxa'):\n",
        "            # Iterate over each 'denominacio' element within the 'fitxa'\n",
        "            for denominacio in fitxa.findall('denominacio'):\n",
        "                if denominacio.get('llengua') == 'es':\n",
        "                    medicalterms_es.add(denominacio.text)\n",
        "                elif denominacio.get('llengua') == 'ca':\n",
        "                    medicalterms_cat.add(denominacio.text)\n",
        "\n",
        "medicalterms_es = list(medicalterms_es)\n",
        "medicalterms_cat = list(medicalterms_cat)\n",
        "print(len(medicalterms_es))\n",
        "print(len(medicalterms_cat))\n",
        "print(medicalterms_es[:20])\n",
        "print(medicalterms_cat[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCL8U0Hal9xd",
        "outputId": "82eb1cb6-5685-4d85-fbf7-d3bd07a97b95"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17052\n",
            "17394\n",
            "['conducto semicircular posterior', 'rinoscopia posterior', 'vacuna antineumocócica conjugada 13-valente', 'sudoresis', 'astigmatismo contra la regla', 'índice de Barthel', 'autoacusación', 'abrebocas', 'dilución', 'cymba conchalis', 'masoterapia', 'contracción paradójica', 'plexo nervioso', 'subículo', 'radiodenso', 'flujo', 'VRE', 'neuritis óptica', 'isquion', 'idea']\n",
            "['múscul constrictor superior de la faringe', 'oftàlmia', 'grànul primari', 'isquèmia retinal', 'siringomièlia', 'fibra arcuada externa', 'limbe de la fossa oval', 'deliri secundari', 'artèria capsular mitjana', 'tromofília', 'anquilosi fibrosa', 'prova unilateral', 'asèpsia', 'iatrogènic -a', 'lligaments de Cooper', 'VRE', 'degeneració hepatolenticular', 'intumescència cervical', 'idea', 'prepart']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyMQAKhg5qlK"
      },
      "source": [
        "#### Import the data (JSON)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-V4PMzZ5pr7",
        "outputId": "be3b2733-eb15-4ea0-ed66-592b5425e720"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98\n",
            "84\n",
            "2955\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "train_data = \"/content/NegExES/data/negacio_train_v2024.json\"\n",
        "\n",
        "with open(train_data, 'r') as file:\n",
        "    json_data = file.read()\n",
        "\n",
        "data = json.loads(json_data)\n",
        "\n",
        "# Extract text and rules from predictions\n",
        "corpus = []\n",
        "rules = []\n",
        "neg, unc, umls = [],[],[]\n",
        "neg_scopes, unc_scopes = [],[]\n",
        "\n",
        "for item in data:\n",
        "    text = item['data']['text']\n",
        "    corpus.append(text)\n",
        "    predictions = item['predictions']\n",
        "    for prediction in predictions:\n",
        "        for result in prediction['result']:\n",
        "            value = result['value']\n",
        "            start = value['start']\n",
        "            end = value['end']\n",
        "            labels = value['labels']\n",
        "            extracted_text = text[start:end]\n",
        "            for label in labels:\n",
        "                if (label == \"NEG\") and (extracted_text not in neg):\n",
        "                    neg.append(extracted_text)\n",
        "                elif (label == \"UNC\") and (extracted_text not in unc):\n",
        "                    unc.append(extracted_text)\n",
        "                elif label == \"NSCO\":\n",
        "                    if extracted_text not in umls:\n",
        "                        umls.append(extracted_text)\n",
        "                    neg_scopes.append((start,end))\n",
        "                elif label == \"USCO\":\n",
        "                    if extracted_text not in umls:\n",
        "                        umls.append(extracted_text)\n",
        "                    unc_scopes.append((start,end))\n",
        "\n",
        "print(len(neg))\n",
        "print(len(unc))\n",
        "print(len(umls))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoRt1TQ5whv-"
      },
      "source": [
        "### Preprocess Rule Tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P33F1Kutx10i",
        "outputId": "1bb567ff-07de-48b9-9d76-c491417f124c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('ausencia de', 'PREN'), ('no pueden ver', 'PREN'), ('no poder', 'PREN'), ('revisado para', 'PREN'), ('rechazado', 'PREN'), ('declina', 'PREN'), ('negado', 'PREN'), ('niega', 'PREN'), ('negando', 'PREN'), ('evaluar por', 'PREN'), ('no revela', 'PREN'), ('libre de', 'PREN'), ('negativo para', 'PREN'), ('nunca desarrollado', 'PREN'), ('nunca tuve', 'PREN'), ('no', 'PREN'), ('no anormal', 'PREN'), ('ninguna causa de', 'PREN'), ('sin quejas de', 'PREN'), ('sin evidencia', 'PREN'), ('ninguna nueva evidencia', 'PREN'), ('ninguna otra evidencia', 'PREN'), ('ninguna evidencia para sugerir', 'PREN'), ('sin hallazgos de', 'PREN'), ('no hay hallazgos para indicar', 'PREN'), ('no hay evidencia mamográfica de', 'PREN'), ('nada nuevo', 'PREN'), ('ninguna evidencia radiográfica de', 'PREN'), ('ninguna señal de', 'PREN'), ('no significativo', 'PREN'), ('sin signos de', 'PREN'), ('ninguna sugerencia de', 'PREN'), ('no sospechoso', 'PREN'), ('no', 'PREN'), ('no aparece', 'PREN'), ('no apreciar', 'PREN'), ('no asociado con', 'PREN'), ('no me quejo de', 'PREN'), ('no demostrar', 'PREN'), ('no exhibir', 'PREN'), ('no sentir', 'PREN'), ('no tenía', 'PREN'), ('no tengo', 'PREN'), ('no saber de', 'PREN'), ('no se sabe que tiene', 'PREN'), ('no revelar', 'PREN'), ('no ver', 'PREN'), ('no ser', 'PREN'), ('paciente no era', 'PREN'), ('más bien que', 'PREN'), ('resuelto', 'PREN'), ('hacer una prueba por', 'PREN'), ('excluir', 'PREN'), ('nada especial para', 'PREN'), ('con ningún', 'PREN'), ('sin ninguna evidencia de', 'PREN'), ('sin evidencia', 'PREN'), ('sin indicación de', 'PREN'), ('sin signo de', 'PREN'), ('sin', 'PREN'), ('descartar para', 'PREN'), ('descartarlo por', 'PREN'), ('descartarla por', 'PREN'), ('descartar al paciente por', 'PREN'), ('descartarlo', 'PREN'), ('descartarla', 'PREN'), ('descartar', 'PREN'), ('r / o', 'PREN'), ('ro', 'PREN'), ('descartar al paciente', 'PREN'), ('excluye', 'PREN'), ('lo descarta', 'PREN'), ('la excluye', 'PREN'), ('expulsó al paciente por', 'PREN'), ('gobierna al paciente', 'PREN'), ('lo descartó contra', 'PREN'), ('la descartó contra', 'PREN'), ('lo descartó', 'PREN'), ('la descartó', 'PREN'), ('descartado contra', 'PREN'), ('descartó al paciente contra', 'PREN'), ('descartaron para', 'PREN'), ('descartaron contra', 'PREN'), ('descartó', 'PREN'), ('lo descartaron por', 'PREN'), ('lo descartaron en contra', 'PREN'), ('lo descartaron', 'PREN'), ('la descartaron por', 'PREN'), ('lo descartó contra', 'PREN'), ('lo descartó', 'PREN'), ('descartaron al paciente contra', 'PREN'), ('descartaron al paciente por', 'PREN'), ('descartó al paciente', 'PREN'), ('puede descartar', 'PREN'), ('puede descartar contra', 'PREN'), ('puede descartar', 'PREN'), ('puede descartarlo por', 'PREN'), ('puede descartarlo en contra', 'PREN'), ('puede descartarlo', 'PREN'), ('puede descartarla por', 'PREN'), ('puede descartarla contra', 'PREN'), ('puede descartarla', 'PREN'), ('puede descartar al paciente por', 'PREN'), ('puede descartar al paciente contra', 'PREN'), ('puede descartar al paciente', 'PREN'), ('adecuado para descartar', 'PREN'), ('adecuado para descartar', 'PREN'), ('adecuado para descartarlo por', 'PREN'), ('adecuado para descartarlo', 'PREN'), ('adecuado para descartarla por', 'PREN'), ('adecuado para descartarla', 'PREN'), ('adecuado para descartar al paciente por', 'PREN'), ('adecuado para descartar al paciente contra', 'PREN'), ('adecuado para descartar al paciente', 'PREN'), ('suficiente para descartar', 'PREN'), ('suficiente para descartar', 'PREN'), ('suficiente para descartar', 'PREN'), ('suficiente para descartarlo por', 'PREN'), ('suficiente para descartarlo en contra', 'PREN'), ('suficiente para descartarlo', 'PREN'), ('suficiente para descartarla por', 'PREN'), ('suficiente para descartarla en contra', 'PREN'), ('suficiente para descartarla', 'PREN'), ('suficiente para descartar al paciente por', 'PREN'), ('suficiente para descartar al paciente contra', 'PREN'), ('suficiente para descartar al paciente', 'PREN'), ('lo que debe descartarse es', 'PREN'), ('debe descartarse para', 'POSTN'), ('debe ser descartado para', 'POSTN'), ('puede ser descartado para', 'POSTN'), ('puede ser descartado para', 'POSTN'), ('podría ser descartado por', 'POSTN'), ('será descartado por', 'POSTN'), ('se puede descartar por', 'POSTN'), ('debe descartarse para', 'POSTN'), ('debe ser descartado por', 'POSTN'), ('ser descartado por', 'POSTN'), ('improbable', 'POSTN'), ('libre', 'POSTN'), ('fue descartado', 'POSTN'), ('está descartado', 'POSTN'), ('están descartadas', 'POSTN'), ('han sido descartadas', 'POSTN'), ('ha sido descartado', 'POSTN'), ('siendo descartado', 'POSTN'), ('debe descartarse', 'POSTN'), ('debe ser descartado', 'POSTN'), ('puede ser descartado', 'POSTN'), ('podría descartarse', 'POSTN'), ('podría ser descartado', 'POSTN'), ('será descartado', 'POSTN'), ('se puede descartar', 'POSTN'), ('debe descartarse', 'POSTN'), ('debe ser descartado', 'POSTN'), ('ser descartado', 'POSTN'), ('se descarta', 'POSTN'), ('sin aumento', 'PSEU'), ('ningún cambio', 'PSEU'), ('sin cambios sospechosos', 'PSEU'), ('ningún cambio significativo', 'PSEU'), ('sin cambio de intervalo', 'PSEU'), ('sin cambio definitivo', 'PSEU'), ('no se extiende', 'PSEU'), ('no causa', 'PSEU'), ('no drena', 'PSEU'), ('cambio de intervalo no significativo', 'PSEU'), ('no estoy seguro si', 'PSEU'), ('no estoy seguro de si', 'PSEU'), ('gram negativo', 'PSEU'), ('sin dificultad', 'PSEU'), ('no necesariamente', 'PSEU'), ('no solo', 'PSEU'), ('duda', 'PSEU'), ('tengo dudas', 'PSEU'), ('dudo', 'PSEU'), ('pero', 'CONJ'), ('sin embargo', 'CONJ'), ('sin embargo', 'CONJ'), ('todavía', 'CONJ'), ('aunque', 'CONJ'), ('a pesar de que', 'CONJ'), ('todavía', 'CONJ'), ('aparte de', 'CONJ'), ('excepto', 'CONJ'), ('aparte de', 'CONJ'), ('secundario a', 'CONJ'), ('como la causa de', 'CONJ'), ('como fuente de', 'CONJ'), ('como la razón de', 'CONJ'), ('como la etiología de', 'CONJ'), ('como el origen de', 'CONJ'), ('como la causa de', 'CONJ'), ('como fuente de', 'CONJ'), ('como la razón de', 'CONJ'), ('como la etiología de', 'CONJ'), ('como el origen de', 'CONJ'), ('como la causa secundaria de', 'CONJ'), ('como la fuente secundaria de', 'CONJ'), ('como la razón secundaria de', 'CONJ'), ('como la etiología secundaria de', 'CONJ'), ('como el origen secundario de', 'CONJ'), ('como la causa secundaria de', 'CONJ'), ('como la fuente secundaria para', 'CONJ'), ('como la razón secundaria para', 'CONJ'), ('como la etiología secundaria para', 'CONJ'), ('como el origen secundario para', 'CONJ'), ('como causa de', 'CONJ'), ('como fuente de', 'CONJ'), ('como una razón de', 'CONJ'), ('como una etiología de', 'CONJ'), ('como causa de', 'CONJ'), ('como fuente de', 'CONJ'), ('como una razón para', 'CONJ'), ('como una etiología para', 'CONJ'), ('como una causa secundaria de', 'CONJ'), ('como una fuente secundaria de', 'CONJ'), ('como una razón secundaria de', 'CONJ'), ('como una etiología secundaria de', 'CONJ'), ('como un origen secundario de', 'CONJ'), ('como una causa secundaria para', 'CONJ'), ('como una fuente secundaria para', 'CONJ'), ('como una razón secundaria para', 'CONJ'), ('como una etiología secundaria para', 'CONJ'), ('como un origen secundario para', 'CONJ'), ('causa de', 'CONJ'), ('motivo de', 'CONJ'), ('causas de', 'CONJ'), ('causas de', 'CONJ'), ('fuente de', 'CONJ'), ('fuente para', 'CONJ'), ('fuentes de', 'CONJ'), ('fuentes para', 'CONJ'), ('razón de', 'CONJ'), ('razón para', 'CONJ'), ('razones de', 'CONJ'), ('razones para', 'CONJ'), ('etiología de', 'CONJ'), ('etiología para', 'CONJ'), ('desencadenar evento para', 'CONJ'), ('origen de', 'CONJ'), ('origen para', 'CONJ'), ('orígenes de', 'CONJ'), ('orígenes para', 'CONJ'), ('otras posibilidades de', 'CONJ')]\n",
            "250\n",
            "84\n"
          ]
        }
      ],
      "source": [
        "# Add rule tags we found to the ones we have from the training dataset\n",
        "\n",
        "with open('/content/NegExES/data/extra_rules.txt', 'r') as file:\n",
        "    file_extra_rules = file.read()\n",
        "\n",
        "extra_rules = []\n",
        "word, tag, is_tag = \"\", \"\", False\n",
        "\n",
        "for char in file_extra_rules:\n",
        "    if char == \"\\n\":\n",
        "        extra_rules.append((word[:-1],tag[:-1]))\n",
        "        word, tag, is_tag = \"\", \"\", False\n",
        "    elif char == \"[\":\n",
        "        is_tag = True\n",
        "    elif is_tag == False:\n",
        "        word += char\n",
        "    elif is_tag == True:\n",
        "        tag += char\n",
        "\n",
        "for rule in extra_rules:\n",
        "    if (rule[1] == \"PREN\") or (rule[1] == \"POSTN\") and (rule[0] not in neg):\n",
        "        neg.append(rule[0])\n",
        "    elif (rule[1] == \"PREP\") or (rule[1] == \"POSTP\") and (rule[0] not in unc):\n",
        "        unc.append(rule[0])\n",
        "\n",
        "print(len(neg))\n",
        "print(len(unc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-PmYfvh2QvY"
      },
      "outputs": [],
      "source": [
        "# Add extra medical terms\n",
        "medical_keywords = ['resultado','efecto','reacción','prueba','respuesta','diagnóstico','presencia','hallazgo','función','riesgo','síntoma','indicación','tratamiento','terapia',\n",
        "                    'análisis','complicación','enfermedad','condición','sensibilidad','exposición''concentración','infección','detección','alteración','nivel','signo','deficiencia',\n",
        "                    'intolerancia','inmunidad','resistencia','capacidad','absorción','secuela','progresión','mejora','rechazo','eficacia','toxicidad','prevención']\n",
        "\n",
        "for word in medical_keywords:\n",
        "    umls.append(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnoq5Nztu8u7"
      },
      "outputs": [],
      "source": [
        "# Clean rules - remove spaces and punctuation + correct spelling mistakes\n",
        "def clean_words(words):\n",
        "    words = [word.strip(\"!?,.;:\") for word in words]\n",
        "    #words = correct_mispellings(words)\n",
        "    words = list(set(words))\n",
        "    return words\n",
        "\n",
        "neg = clean_words(neg)\n",
        "unc = clean_words(unc)\n",
        "umls = clean_words(umls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtEEMVLLwluO"
      },
      "source": [
        "### Preprocess Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JXD8BbL5tux"
      },
      "source": [
        "#### Correct mispelled words or lemmatise them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HVzvPIu6EuA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNw6pEXq6NU6"
      },
      "source": [
        "#### Keep or remove punctuation (depending on algorithm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fruaWxQa6SN_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMuE3NRS6Ylc"
      },
      "source": [
        "#### Split text into individual sentences (depending on algorithm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fq2IjjB26eEK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKn48OyK6fAm"
      },
      "source": [
        "#### Remove patient information at the start to avoid false positives (?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2CHjjjT6lV_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fDN7wXx6nGr"
      },
      "source": [
        "#### Tokenize (keep coordinates of original text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfgm2vjl6qQL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca9yC8jplxyG"
      },
      "source": [
        "# NegEx algorithm\n",
        "\n",
        "- input = sentence with indexed diseases/findings\n",
        "- output = sentence with indexed negated diseases/findings\n",
        "\n",
        "PROCESS\n",
        "\n",
        "- one sentence per line\n",
        "- remove all punctuation, don't remove stop words\n",
        "- index diseases/findings by replacing phrases in text with unique string identifiers IDs from UMLS. If sentence has no UMLS term --> no search for negatives.\n",
        "\n",
        "Ex: \"*The patient denied experiencing chest pain on exertion*\" --> \"*The patient denied experiencing S1459038 on exertion*\"\n",
        "\n",
        "- The string matching algorithm matches the longest possible string among eligible matches in UMLS. Ex: it will match \"*nonspecific viral rash*\" instead of just \"*rash*\".\n",
        "\n",
        "RESULTS\n",
        "- They identified 35 negation phrases that could be divided in 2 groups:\n",
        "1. Pseudo negation phrases: appear to indicate negation but instead identify double negatives (\"not ruled out\"), modified meanings (\"gram-negative\") and ambiguous phrasing (\"unremarkable\")\n",
        "2. Phrases used to negate diseases/findings when used in one of this regular expressions:\n",
        "- (*negation phrase*) * (**UMLS term**)\n",
        "- (**UMLS term**) * (*negation phrase*)\n",
        "- \"*\" = up to 5 tokens may fall between negation phrase and UMLS term\n",
        "- Ex: \"extremities showed *no* **cyanosis**, clubbing, or **edema**\" matches (no) * (UMLS term) twice with both cyanosis and edema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIUtz8Gdx6GC"
      },
      "source": [
        "# NegEx algorithm implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRhb-jxS-uYg"
      },
      "source": [
        "Implementations:\n",
        "- https://github.com/PlanTL-GOB-ES/NegEx-MES --> for spanish datasets: https://github.com/PlanTL-GOB-ES/NegEx-MES/tree/master/smn/config_files/spa\n",
        "- https://github.com/chapmanbe/negex/tree/master/negex.python --> code implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdJIAzP26TGW"
      },
      "outputs": [],
      "source": [
        "def negations_and_scopes(text,neg,umls):\n",
        "    \"\"\"\n",
        "    Detect negations and its scopes in texts from corpus\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def uncertainity_and_scopes(text,unc,umls):\n",
        "    \"\"\"\n",
        "    Detect negations and its scopes in texts from corpus\n",
        "    \"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "QNiqHM287x82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_neg, pred_neg_scopes = [],[]\n",
        "pred_unc, pred_unc_scopes = [],[]\n",
        "\n",
        "for text in corpus:\n",
        "    pred_neg_, pred_neg_scopes_ = negations_and_scopes(text,neg,umls)\n",
        "    pred_unc_, pred_unc_scopes_ = uncertainity_and_scopes(text,unc,umls)\n",
        "    pred_neg.extend(pred_neg_)\n",
        "    pred_neg_scopes.extend(pred_neg_scopes_)\n",
        "    pred_unc.extend(pred_unc_)\n",
        "    pred_unc_scopes.extend(pred_unc_scopes_)"
      ],
      "metadata": {
        "id": "RCDwbhu771SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rule-based method Evaluation"
      ],
      "metadata": {
        "id": "0eQRMpa08tdr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NsY0seOj8yFa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}